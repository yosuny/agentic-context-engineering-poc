
import os
import sys
import json
from typing import List, Dict, Any

# Add ace directory to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../ace')))

from ace import ACE
from utils import initialize_clients

def run_performance_pilot():
    print("\nðŸš€ Starting ACE Performance Pilot Test (Baseline vs ACE)...")
    
    # 1. Initialize ACE System
    api_provider = "ncloud"
    client, _, _ = initialize_clients(api_provider)
    
    ace_system = ACE(
        api_provider=api_provider,
        generator_model="HCX-007",
        reflector_model="HCX-007",
        curator_model="HCX-007",
        max_tokens=2048
    )

    # 2. Define the Test Question
    question = "15ì–µ ì•„íŒŒíŠ¸ë¥¼ 5ë…„ ë³´ìœ  ë° ê±°ì£¼í•œ 1ì„¸ëŒ€ 1ì£¼íƒìžì˜ ì–‘ë„ì†Œë“ì„¸ ê³„ì‚° ê³¼ì •ê³¼ ì˜ˆìƒ ì„¸ì•¡ì„ ì•Œë ¤ì£¼ì„¸ìš”. (ì·¨ë“ê°€ì•¡ì€ 10ì–µìœ¼ë¡œ ê°€ì •)"

    # 3. Get Baseline Response (Empty Playbook)
    print("\n[A] Generating Baseline Response (No Playbook)...")
    baseline_response, _, _ = ace_system.generator.generate(
        question=question,
        playbook="",  # Empty playbook for baseline
        context="",
        reflection="(none)",
        call_id="pilot_baseline"
    )

    # 4. Get ACE Augmented Response (Using Evolved Playbook from Phase 3)
    # We'll use the playbook evolved in Phase 3
    evolved_playbook = """## STRATEGIES & INSIGHTS

## FORMULAS & CALCULATIONS
[calc-00001] ì–‘ë„ì†Œë“ì„¸ ë¹„ê³¼ì„¸ ìš”ê±´ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê³µì‹ ë° ê³„ì‚° ë‹¨ê³„. 1ì„¸ëŒ€ 1ì£¼íƒìžì˜ ê²½ìš° 12ì–µ ì›ê¹Œì§€ëŠ” ë¹„ê³¼ì„¸ì´ë©°, ì´ë¥¼ ì´ˆê³¼í•˜ëŠ” ë¶€ë¶„ì— ëŒ€í•´ì„œë§Œ ê³¼ì„¸í•©ë‹ˆë‹¤.
[calc-00004] ê³ ê°€ì£¼íƒì˜ ì–‘ë„ì°¨ìµ ê³„ì‚° ì‹œ, (ì–‘ë„ê°€ì•¡ - 12ì–µ) / ì–‘ë„ê°€ì•¡ ë¹„ìœ¨ì„ ì „ì²´ ì–‘ë„ì°¨ìµì— ê³±í•˜ì—¬ ê³¼ì„¸ëŒ€ìƒ ì–‘ë„ì°¨ìµì„ ì‚°ì¶œí•©ë‹ˆë‹¤.
[calc-00006] ìž¥ê¸°ë³´ìœ íŠ¹ë³„ê³µì œëŠ” 1ì„¸ëŒ€ 1ì£¼íƒìžì˜ ê²½ìš° ë³´ìœ  ê¸°ê°„ë³„ ì—° 4%, ê±°ì£¼ ê¸°ê°„ë³„ ì—° 4%ë¥¼ í•©ì‚°í•˜ì—¬ ìµœëŒ€ 80%ê¹Œì§€ ê³µì œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (10ë…„ ì´ìƒ ë³´ìœ /ê±°ì£¼ ì‹œ)

## COMMON MISTAKES TO AVOID
[err-00002] 12ì–µ ì› ì´í•˜ ì£¼íƒì´ë¼ê³  í•´ì„œ ë¬´ì¡°ê±´ ë¹„ê³¼ì„¸ê°€ ì•„ë‹ˆë©°, 2ë…„ ì´ìƒ ë³´ìœ (ì¡°ì •ì§€ì—­ì€ ê±°ì£¼ í¬í•¨) ìš”ê±´ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.

## OTHERS
[misc-00007] ìƒì†ì£¼íƒ ë“± ì¼ì‹œì  2ì£¼íƒ íŠ¹ë¡€ê°€ ì ìš©ë˜ëŠ”ì§€ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
"""
    
    print("\n[B] Generating ACE Augmented Response (With Evolved Playbook)...")
    ace_response, _, _ = ace_system.generator.generate(
        question=question,
        playbook=evolved_playbook,
        context="",
        reflection="(none)",
        call_id="pilot_ace"
    )

    # 5. Display Comparison
    print("\n" + "="*80)
    print("SIDE-BY-SIDE COMPARISON")
    print("="*80)
    
    print("\n[BASELINE RESPONSE]")
    print("-" * 20)
    print(baseline_response)
    
    print("\n" + "="*40)
    
    print("\n[ACE AUGMENTED RESPONSE]")
    print("-" * 20)
    print(ace_response)
    print("="*80)

    # 6. Save Comparison Report
    report_path = "tests/pilot_comparison_report.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("# ACE Performance Pilot Comparison Report\n\n")
        f.write("## 1. Test Question\n")
        f.write(f"> {question}\n\n")
        f.write("## 2. Comparison Results\n\n")
        f.write("### [A] Baseline (No Playbook)\n")
        f.write("```text\n" + baseline_response + "\n```\n\n")
        f.write("### [B] ACE Augmented (Phase 3 Playbook)\n")
        f.write("```text\n" + ace_response + "\n```\n\n")
        f.write("## 3. Analysis\n")
        f.write("- **Correctness**: Did the model use the 12ì–µ threshold correctly?\n")
        f.write("- **Precision**: Did it calculate the tax ratio for high-value property correctly?\n")
        f.write("- **Specifics**: Was the Long-term Special Deduction (ìž¥íŠ¹ê³µì œ) accuracy improved?\n")

    print(f"\nâœ… Pilot Comparison Report saved to: {report_path}")

if __name__ == "__main__":
    run_performance_pilot()
